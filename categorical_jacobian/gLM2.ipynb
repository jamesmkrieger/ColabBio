{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sokrypton/ColabBio/blob/main/categorical_jacobian/gLM2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Categorical Jacobian on gLM2"
      ],
      "metadata": {
        "id": "GD9_fkFDPUas"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwhOjguxaA0k",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@markdown ## setup gLM2_650M\n",
        "import os\n",
        "os.system(\"pip -q install --no-dependencies flash_attn\")\n",
        "\n",
        "MODEL_NAME = \"tattabio/gLM2_650M\"\n",
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "DEVICE = \"cuda\"\n",
        "MODEL = AutoModelForMaskedLM.from_pretrained(MODEL_NAME, trust_remote_code=True).eval().to(DEVICE)\n",
        "TOKENIZER = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "MASK_ID = TOKENIZER.convert_tokens_to_ids('<mask>')\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from string import ascii_uppercase, ascii_lowercase\n",
        "alphabet_list = list(ascii_uppercase+ascii_lowercase)\n",
        "\n",
        "\n",
        "TQDM_BAR_FORMAT = '{l_bar}{bar}| {n_fmt}/{total_fmt} [elapsed: {elapsed} remaining: {remaining}]'\n",
        "\n",
        "def get_categorical_jacobian(seqs, prepend_seq=\"<+>\", fast=False):\n",
        "  # ∂in/∂out\n",
        "\n",
        "  xs = []\n",
        "  masks = []\n",
        "  for seq in seqs:\n",
        "    if len(seq) > 0:\n",
        "      x = TOKENIZER([prepend_seq+seq])[\"input_ids\"][0]\n",
        "      mask = np.pad(np.full(len(seq),True),[len(x)-len(seq),0])\n",
        "      xs.append(x)\n",
        "      masks.append(mask)\n",
        "\n",
        "  x = torch.tensor(np.concatenate(xs,-1)[None]).to(DEVICE)\n",
        "  mask = np.concatenate(masks,-1)\n",
        "\n",
        "  with torch.no_grad(), torch.cuda.amp.autocast(enabled=True):\n",
        "    f = lambda x: MODEL(x).logits[:, :, 4:24].detach().cpu().numpy()\n",
        "    fx = f(x.to(DEVICE))[0][mask]\n",
        "\n",
        "    ln = sum(mask)\n",
        "    if fast:\n",
        "      fx_h = np.zeros([ln, 1 , ln, 20], dtype=np.float32)\n",
        "      x = x.to(DEVICE)\n",
        "    else:\n",
        "      fx_h = np.zeros([ln, 20, ln, 20], dtype=np.float32)\n",
        "      x = torch.tile(x, [20, 1]).to(DEVICE)\n",
        "\n",
        "    with tqdm.notebook.tqdm(total=ln, bar_format=TQDM_BAR_FORMAT) as pbar:\n",
        "      i = 0\n",
        "      for n in range(len(mask)):  # for each position\n",
        "        x_h = torch.clone(x)\n",
        "        if mask[n]:\n",
        "          # mutate to all 20 aa\n",
        "          if fast:\n",
        "            x_h[:, n] = MASK_ID\n",
        "          else:\n",
        "            x_h[:, n] = torch.arange(4, 24)\n",
        "          fx_h[i] = f(x_h)[:,mask]\n",
        "          i += 1\n",
        "          pbar.update(1)\n",
        "\n",
        "    return fx_h - fx\n",
        "\n",
        "def J_to_contact_map(J):\n",
        "  J_copy = J.copy()\n",
        "  # center\n",
        "  for k in range(4):\n",
        "    if J_copy.shape[k] > 1:\n",
        "      J_copy -= J_copy.mean(k,keepdims=True)\n",
        "\n",
        "  # l2norm\n",
        "  raw = np.sqrt(np.square(J_copy).sum((1,3)))\n",
        "  np.fill_diagonal(raw, 0)\n",
        "\n",
        "  # apc\n",
        "  apc = raw - (raw.sum(0,keepdims=True) * raw.sum(1,keepdims=True)) / raw.sum()\n",
        "  np.fill_diagonal(apc, 0)\n",
        "\n",
        "  # symm\n",
        "  apc = (apc + apc.T)/2\n",
        "\n",
        "  return raw, apc\n",
        "\n",
        "def plot_ticks(Ls, axes=None):\n",
        "  if axes is None: axes = plt.gca()\n",
        "  Ln = sum(Ls)\n",
        "  L_prev = 0\n",
        "  for L_i in Ls[:-1]:\n",
        "    L = L_prev + L_i\n",
        "    L_prev += L_i\n",
        "    plt.plot([0,Ln],[L,L],color=\"black\")\n",
        "    plt.plot([L,L],[0,Ln],color=\"black\")\n",
        "  ticks = np.cumsum([0]+Ls)\n",
        "  ticks = (ticks[1:] + ticks[:-1])/2\n",
        "  axes.set_yticks(ticks)\n",
        "  axes.set_yticklabels(alphabet_list[:len(ticks)])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ## input sequence(s)\n",
        "\n",
        "seq_A = \"MRILPISTIKGKLNEFVDAVSSTQDQITITKNGAPAAVLVGADEWESLQETLYWLAQPGIRESIAEADADIASGRTYGEDEIRAEFGVPRRPHDYKDDDDK\" # @param {type:\"string\"}\n",
        "seq_B = \"PYTVRFTTTARRDLHKLPPRILAAVVEFAFGDLSREPLRVGKPLRRELAGTFSARRGTYRLLYRIDDEHTTVVILRVDHRADIYRR\" # @param {type:\"string\"}\n",
        "seq_C = \"\" # @param {type:\"string\"}\n",
        "seq_D = \"\" # @param {type:\"string\"}\n",
        "seq_E = \"\" # @param {type:\"string\"}\n",
        "seq_F = \"\" # @param {type:\"string\"}\n",
        "#@markdown settings\n",
        "#@markdown ---\n",
        "seperator = \"<->\" # @param [\"<+>\",\"<->\",\"\"]\n",
        "fast = False # @param {type:\"boolean\"}\n",
        "#@markdown - `fast`=`True` - only perturb the `mask` token\n",
        "\n",
        "\n",
        "seqs = []\n",
        "Ls = []\n",
        "for seq in [seq_A,seq_B,seq_C,seq_D,seq_E,seq_F]:\n",
        "  seq = seq.replace(\" \",\"\")\n",
        "  if len(seq) > 0:\n",
        "    seqs.append(''.join([i for i in seq.upper() if i.isalpha()]))\n",
        "    Ls.append(len(seq))\n",
        "\n",
        "J = get_categorical_jacobian(seqs,\n",
        "                             prepend_seq=seperator,\n",
        "                             fast=fast)\n",
        "\n",
        "raw, apc = J_to_contact_map(J)\n",
        "L = apc.shape[0]\n",
        "plt.figure(figsize=(5,5),dpi=200)\n",
        "plt.imshow(apc,cmap=\"Blues\", interpolation='none',\n",
        "           extent=(0, L, L, 0))\n",
        "plot_ticks(Ls)\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "GOLmeBEu7veZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMC7N3ypLEn5ndckG4+3Xuc",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}