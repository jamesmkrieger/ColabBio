{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3f97d6d3c538478db0340d049d39d04a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b849e0da03a34d859b670b41cf53693f",
              "IPY_MODEL_fe5299bf94024d62b29f1b0665774a40",
              "IPY_MODEL_62fdb4848300453d9cc75eb394ed800c"
            ],
            "layout": "IPY_MODEL_f2978d6ed73b4a1cbab1b40f6aafa23a"
          }
        },
        "b849e0da03a34d859b670b41cf53693f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02ba8f194664479c9ed9e4702792aaee",
            "placeholder": "​",
            "style": "IPY_MODEL_47b3b4b977114daf82bf72ac36a6fbb2",
            "value": "  0%"
          }
        },
        "fe5299bf94024d62b29f1b0665774a40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0960c4d985d4858a3dba02f92faed0d",
            "max": 3552,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_22c6c5bf23b34519b77d8c3641983883",
            "value": 0
          }
        },
        "62fdb4848300453d9cc75eb394ed800c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41da03df75664d6bba98c454f3794274",
            "placeholder": "​",
            "style": "IPY_MODEL_6edb57893f2643908c2ac56a135f7ba0",
            "value": " 0/3552 [elapsed: 00:01 remaining: ?]"
          }
        },
        "f2978d6ed73b4a1cbab1b40f6aafa23a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02ba8f194664479c9ed9e4702792aaee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47b3b4b977114daf82bf72ac36a6fbb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0960c4d985d4858a3dba02f92faed0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22c6c5bf23b34519b77d8c3641983883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41da03df75664d6bba98c454f3794274": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6edb57893f2643908c2ac56a135f7ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamesmkrieger/ColabBio/blob/main/categorical_jacobian/esm2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**get Categorical Jacobian from ESM2**\n",
        "##(aka. extract conservation and coevolution for your favorite protein)"
      ],
      "metadata": {
        "id": "wqjacq79TckC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtRKmskxgHfs",
        "outputId": "c092a8c5-ff50-410b-d1de-a32e7874be25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "#@markdown ##setup model\n",
        "model_name = \"esm2_t33_650M_UR50D\" # @param [\"esm2_t48_15B_UR50D\",\"esm2_t36_3B_UR50D\",\"esm2_t33_650M_UR50D\",\"esm2_t30_150M_UR50D\",\"esm2_t12_35M_UR50D\",\"esm2_t6_8M_UR50D\",\"esm1b_t33_650M_UR50S\"]\n",
        "# this step will take ~3mins\n",
        "import torch\n",
        "import os\n",
        "if not os.path.isfile(\"utils.py\"):\n",
        "  os.system(\"wget -qnc https://raw.githubusercontent.com/sokrypton/ColabBio/main/categorical_jacobian/utils.py\")\n",
        "  os.system(\"apt-get install aria2 -qq\")\n",
        "  os.system(\"mkdir -p /root/.cache/torch/hub/checkpoints/\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import bokeh.plotting\n",
        "bokeh.io.output_notebook()\n",
        "from bokeh.models import BasicTicker, PrintfTickFormatter\n",
        "from bokeh.palettes import viridis, RdBu\n",
        "from bokeh.transform import linear_cmap\n",
        "from bokeh.plotting import figure, show\n",
        "\n",
        "from matplotlib.colors import to_hex\n",
        "cmap = plt.colormaps[\"bwr_r\"]\n",
        "bwr_r = [to_hex(cmap(i)) for i in np.linspace(0, 1, 256)]\n",
        "cmap = plt.colormaps[\"gray_r\"]\n",
        "gray = [to_hex(cmap(i)) for i in np.linspace(0, 1, 256)]\n",
        "\n",
        "def pssm_to_dataframe(pssm, esm_alphabet):\n",
        "  sequence_length = pssm.shape[0]\n",
        "  idx = [str(i) for i in np.arange(1, sequence_length + 1)]\n",
        "  df = pd.DataFrame(pssm, index=idx, columns=list(esm_alphabet))\n",
        "  df = df.stack().reset_index()\n",
        "  df.columns = ['Position', 'Amino Acid', 'Probability']\n",
        "  return df\n",
        "\n",
        "def contact_to_dataframe(con):\n",
        "  sequence_length = con.shape[0]\n",
        "  idx = [str(i) for i in np.arange(1, sequence_length + 1)]\n",
        "  df = pd.DataFrame(con, index=idx, columns=idx)\n",
        "  df = df.stack().reset_index()\n",
        "  df.columns = ['i', 'j', 'value']\n",
        "  return df\n",
        "\n",
        "def pair_to_dataframe(pair,esm_alphabet):\n",
        "  sequence_length = pair.shape[0]\n",
        "  df = pd.DataFrame(pair, index=list(esm_alphabet), columns=list(esm_alphabet))\n",
        "  df = df.stack().reset_index()\n",
        "  df.columns = ['aa_i', 'aa_j', 'value']\n",
        "  return df\n",
        "\n",
        "from utils import *\n",
        "import tqdm.notebook\n",
        "\n",
        "TQDM_BAR_FORMAT = '{l_bar}{bar}| {n_fmt}/{total_fmt} [elapsed: {elapsed} remaining: {remaining}]'\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def load_model(model_name=\"esm2_t36_3B_UR50D\"):\n",
        "  if not os.path.isfile(f\"/root/.cache/torch/hub/checkpoints/{model_name}.pt\"):\n",
        "    os.system(f\"aria2c -q -x 16 -d /root/.cache/torch/hub/checkpoints/ https://dl.fbaipublicfiles.com/fair-esm/models/{model_name}.pt\")\n",
        "    os.system(f\"aria2c -q -x 16 -d /root/.cache/torch/hub/checkpoints/ https://dl.fbaipublicfiles.com/fair-esm/regression/{model_name}-contact-regression.pt\")\n",
        "  model, alphabet = torch.hub.load(\"facebookresearch/esm:main\", model_name)\n",
        "  model = model.to(DEVICE)\n",
        "  model = model.eval()\n",
        "  return model, alphabet\n",
        "\n",
        "def get_logits(seq, p=1, return_jac=False):\n",
        "  x,ln = alphabet.get_batch_converter()([(None,seq)])[-1],len(seq)\n",
        "  if p is None: p = ln\n",
        "  with torch.no_grad():\n",
        "    f = lambda x: model(x)[\"logits\"][:,1:(ln+1),4:24].detach().cpu().numpy()\n",
        "    logits = np.zeros((ln,20), dtype=np.float32)\n",
        "    if return_jac:\n",
        "      jac = np.zeros((ln,1,ln,20), dtype=np.float32)\n",
        "      fx = f(x.to(DEVICE))[0]\n",
        "    with tqdm.notebook.tqdm(total=ln, bar_format=TQDM_BAR_FORMAT) as pbar:\n",
        "      for n in range(0,ln,p):\n",
        "        m = min(n+p,ln)\n",
        "        x_h = torch.tile(torch.clone(x),[m-n,1])\n",
        "        for i in range(m-n):\n",
        "          x_h[i,n+i+1] = alphabet.mask_idx\n",
        "        fx_h = f(x_h.to(DEVICE))\n",
        "        for i in range(m-n):\n",
        "          logits[n+i] = fx_h[i,n+i]\n",
        "          if return_jac:\n",
        "            jac[n+i] = fx_h[i,None] - fx\n",
        "        pbar.update(m-n)\n",
        "    if return_jac:\n",
        "      return jac\n",
        "    else:\n",
        "      return logits\n",
        "\n",
        "def get_categorical_jacobian(seq, layer=None, fast=False):\n",
        "  # ∂in/∂out\n",
        "  x, ln = alphabet.get_batch_converter()([(\"seq\", seq)])[-1], len(seq)\n",
        "  with torch.no_grad():\n",
        "    if layer is None:\n",
        "      f = lambda x: model(x)[\"logits\"][..., 1:(ln+1), 4:24].detach().cpu().numpy()\n",
        "    else:\n",
        "      f = lambda x: model(x, repr_layers=[layer])[\"representations\"][layer][..., 1:(ln+1), :].detach().cpu().numpy()\n",
        "\n",
        "    fx = f(x.to(DEVICE))[0]\n",
        "    fx_h = np.zeros([ln, 1 if fast else 20, ln, fx.shape[-1]], dtype=np.float32)\n",
        "    x = x.to(DEVICE) if fast else torch.tile(x, [20, 1]).to(DEVICE)\n",
        "    with tqdm.notebook.tqdm(total=ln, bar_format=TQDM_BAR_FORMAT) as pbar:\n",
        "      for n in range(ln):  # for each position\n",
        "        x_h = torch.clone(x)\n",
        "\n",
        "        # mutate to all 20 aa\n",
        "        x_h[:, n+1] = alphabet.mask_idx if fast else torch.arange(4, 24)\n",
        "        fx_h[n] = f(x_h)\n",
        "        pbar.update(1)\n",
        "\n",
        "  # note: direction here differs from manuscript\n",
        "  # positive = good\n",
        "  # negative = bad\n",
        "  return fx_h - fx\n",
        "\n",
        "model, alphabet = load_model(model_name)\n",
        "esm_alphabet_len = len(alphabet.all_toks)\n",
        "esm_alphabet = list(\"\".join(alphabet.all_toks[4:24]))\n",
        "ALPHABET = \"AFILVMWYDEKRHNQSTGPC\"\n",
        "ALPHABET_map = [esm_alphabet.index(a) for a in ALPHABET]\n",
        "\n",
        "def jac_to_con(jac, center=True, diag=\"remove\", apc=True):\n",
        "\n",
        "  X = jac.copy()\n",
        "  Lx,Ax,Ly,Ay = X.shape\n",
        "  if Ax == 20:\n",
        "    X = X[:,ALPHABET_map,:,:]\n",
        "\n",
        "  if Ay == 20:\n",
        "    X = X[:,:,:,ALPHABET_map]\n",
        "    if symm and Ax == 20:\n",
        "      X = (X + X.transpose(2,3,0,1))/2\n",
        "\n",
        "  if center:\n",
        "    for i in range(4):\n",
        "      if X.shape[i] > 1:\n",
        "        X -= X.mean(i,keepdims=True)\n",
        "\n",
        "  contacts = np.sqrt(np.square(X).sum((1,3)))\n",
        "\n",
        "  if symm and (Ax != 20 or Ay != 20):\n",
        "    contacts = (contacts + contacts.T)/2\n",
        "\n",
        "  if diag == \"remove\":\n",
        "    np.fill_diagonal(contacts,0)\n",
        "\n",
        "  if diag == \"normalize\":\n",
        "    contacts_diag = np.diag(contacts)\n",
        "    contacts = contacts / np.sqrt(contacts_diag[:,None] * contacts_diag[None,:])\n",
        "\n",
        "  if apc:\n",
        "    ap = contacts.sum(0,keepdims=True) * contacts.sum(1, keepdims=True) / contacts.sum()\n",
        "    contacts = contacts - ap\n",
        "\n",
        "  if diag == \"remove\":\n",
        "    np.fill_diagonal(contacts,0)\n",
        "\n",
        "  return {\"jac\":X, \"contacts\":contacts}"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://github.com/facebookresearch/esm/zipball/main\" to /root/.cache/torch/hub/main.zip\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 10.9 s, sys: 3.77 s, total: 14.7 s\n",
            "Wall time: 54.6 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##enter sequence\n",
        "\n",
        "sequence = \"MGQSVLRAVFFLVLGLLGHSHGGFPNTISIGGLFMRNTVQEHSAFRFAVQLYNTNQNTTE KPFHLNYHVDHLDSSNSFSVTNAFCSQFSRGVYAIFGFYDQMSMNTLTSFCGALHTSFVT PSFPTDADVQFVIQMRPALKGAILSLLSYYKWEKFVYLYDTERGFSVLQAIMEAAVQNNW QVTARSVGNIKDVQEFRRIIEEMDRRQEKRYLIDCEVERINTILEQVVILGKHSRGYHYM LANLGFTDILLERVMHGGANITGFQIVNNENPMVQQFIQRWVRLDEREFPEAKNAPLKYT SALTHDAILVIAEAFRYLRRQRVDVSRRGSAGDCLANPAVPWSQGIDIERALKMVQVQGM TGNIQFDTYGRRTNYTIDVYEMKVSGSRKAGYWNEYERFVPFSDQQISNDSSSSENRTIV VTTILESPYVMYKKNHEQLEGNERYEGYCVDLAYEIAKHVRIKYKLSIVGDGKYGARDPE TKIWNGMVGELVYGRADIAVAPLTITLVREEVIDFSKPFMSLGISIMIKKPQKSKPGVFS FLDPLAYEIWMCIVFAYIGVSVVLFLVSRFSPYEWHLEDNNEEPRDPQSPPDPPNEFGIF NSLWFSLGAFMQQGCDISPRSLSGRIVGGVWWFFTLIIISSYTANLAAFLTVERMVSPIE SAEDLAKQTEIAYGTLDSGSTKEFFRRSKIAVYEKMWSYMKSAEPSVFTKTTADGVARVR KSKGKFAFLLESTMNEYIEQRKPCDTMKVGGNLDSKGYGVATPKGSALGNAVNLAVLKLN EQGLLDKLKNKWWYDKGECGSGGGDSKDKTSALSLSNVAGVFYILVGGLGLAMMVALIEF CYKSRAESKRMKLTKNTQNFKPAPATNTQNYATYREGYNVYGTESVKIMGQSVLRAVFFLVLGLLGHSHGGFPNTISIGGLFMRNTVQEHSAFRFAVQLYNTNQNTTE KPFHLNYHVDHLDSSNSFSVTNAFCSQFSRGVYAIFGFYDQMSMNTLTSFCGALHTSFVT PSFPTDADVQFVIQMRPALKGAILSLLSYYKWEKFVYLYDTERGFSVLQAIMEAAVQNNW QVTARSVGNIKDVQEFRRIIEEMDRRQEKRYLIDCEVERINTILEQVVILGKHSRGYHYM LANLGFTDILLERVMHGGANITGFQIVNNENPMVQQFIQRWVRLDEREFPEAKNAPLKYT SALTHDAILVIAEAFRYLRRQRVDVSRRGSAGDCLANPAVPWSQGIDIERALKMVQVQGM TGNIQFDTYGRRTNYTIDVYEMKVSGSRKAGYWNEYERFVPFSDQQISNDSSSSENRTIV VTTILESPYVMYKKNHEQLEGNERYEGYCVDLAYEIAKHVRIKYKLSIVGDGKYGARDPE TKIWNGMVGELVYGRADIAVAPLTITLVREEVIDFSKPFMSLGISIMIKKPQKSKPGVFS FLDPLAYEIWMCIVFAYIGVSVVLFLVSRFSPYEWHLEDNNEEPRDPQSPPDPPNEFGIF NSLWFSLGAFMQQGCDISPRSLSGRIVGGVWWFFTLIIISSYTANLAAFLTVERMVSPIE SAEDLAKQTEIAYGTLDSGSTKEFFRRSKIAVYEKMWSYMKSAEPSVFTKTTADGVARVR KSKGKFAFLLESTMNEYIEQRKPCDTMKVGGNLDSKGYGVATPKGSALGNAVNLAVLKLN EQGLLDKLKNKWWYDKGECGSGGGDSKDKTSALSLSNVAGVFYILVGGLGLAMMVALIEF CYKSRAESKRMKLTKNTQNFKPAPATNTQNYATYREGYNVYGTESVKIMGQSVLRAVFFLVLGLLGHSHGGFPNTISIGGLFMRNTVQEHSAFRFAVQLYNTNQNTTE KPFHLNYHVDHLDSSNSFSVTNAFCSQFSRGVYAIFGFYDQMSMNTLTSFCGALHTSFVT PSFPTDADVQFVIQMRPALKGAILSLLSYYKWEKFVYLYDTERGFSVLQAIMEAAVQNNW QVTARSVGNIKDVQEFRRIIEEMDRRQEKRYLIDCEVERINTILEQVVILGKHSRGYHYM LANLGFTDILLERVMHGGANITGFQIVNNENPMVQQFIQRWVRLDEREFPEAKNAPLKYT SALTHDAILVIAEAFRYLRRQRVDVSRRGSAGDCLANPAVPWSQGIDIERALKMVQVQGM TGNIQFDTYGRRTNYTIDVYEMKVSGSRKAGYWNEYERFVPFSDQQISNDSSSSENRTIV VTTILESPYVMYKKNHEQLEGNERYEGYCVDLAYEIAKHVRIKYKLSIVGDGKYGARDPE TKIWNGMVGELVYGRADIAVAPLTITLVREEVIDFSKPFMSLGISIMIKKPQKSKPGVFS FLDPLAYEIWMCIVFAYIGVSVVLFLVSRFSPYEWHLEDNNEEPRDPQSPPDPPNEFGIF NSLWFSLGAFMQQGCDISPRSLSGRIVGGVWWFFTLIIISSYTANLAAFLTVERMVSPIE SAEDLAKQTEIAYGTLDSGSTKEFFRRSKIAVYEKMWSYMKSAEPSVFTKTTADGVARVR KSKGKFAFLLESTMNEYIEQRKPCDTMKVGGNLDSKGYGVATPKGSALGNAVNLAVLKLN EQGLLDKLKNKWWYDKGECGSGGGDSKDKTSALSLSNVAGVFYILVGGLGLAMMVALIEF CYKSRAESKRMKLTKNTQNFKPAPATNTQNYATYREGYNVYGTESVKIMGQSVLRAVFFLVLGLLGHSHGGFPNTISIGGLFMRNTVQEHSAFRFAVQLYNTNQNTTE KPFHLNYHVDHLDSSNSFSVTNAFCSQFSRGVYAIFGFYDQMSMNTLTSFCGALHTSFVT PSFPTDADVQFVIQMRPALKGAILSLLSYYKWEKFVYLYDTERGFSVLQAIMEAAVQNNW QVTARSVGNIKDVQEFRRIIEEMDRRQEKRYLIDCEVERINTILEQVVILGKHSRGYHYM LANLGFTDILLERVMHGGANITGFQIVNNENPMVQQFIQRWVRLDEREFPEAKNAPLKYT SALTHDAILVIAEAFRYLRRQRVDVSRRGSAGDCLANPAVPWSQGIDIERALKMVQVQGM TGNIQFDTYGRRTNYTIDVYEMKVSGSRKAGYWNEYERFVPFSDQQISNDSSSSENRTIV VTTILESPYVMYKKNHEQLEGNERYEGYCVDLAYEIAKHVRIKYKLSIVGDGKYGARDPE TKIWNGMVGELVYGRADIAVAPLTITLVREEVIDFSKPFMSLGISIMIKKPQKSKPGVFS FLDPLAYEIWMCIVFAYIGVSVVLFLVSRFSPYEWHLEDNNEEPRDPQSPPDPPNEFGIF NSLWFSLGAFMQQGCDISPRSLSGRIVGGVWWFFTLIIISSYTANLAAFLTVERMVSPIE SAEDLAKQTEIAYGTLDSGSTKEFFRRSKIAVYEKMWSYMKSAEPSVFTKTTADGVARVR KSKGKFAFLLESTMNEYIEQRKPCDTMKVGGNLDSKGYGVATPKGSALGNAVNLAVLKLN EQGLLDKLKNKWWYDKGECGSGGGDSKDKTSALSLSNVAGVFYILVGGLGLAMMVALIEF CYKSRAESKRMKLTKNTQNFKPAPATNTQNYATYREGYNVYGTESVKI\" # @param {type:\"string\"}\n",
        "sequence = sequence.upper().replace(' ', '')\n",
        "print(len(sequence))\n",
        "sequence = ''.join([i for i in sequence if i.isalpha()])\n",
        "\n",
        "PARALLEL = 20\n",
        "if len(sequence) > 1500:\n",
        "  PARALLEL = 10\n",
        "elif len(sequence) > 2400:\n",
        "  PARALLEL = 1\n",
        "\n",
        "os.makedirs(\"output\",exist_ok=True)\n",
        "with open(\"output/README.txt\",\"w\") as handle:\n",
        "  handle.write(\"conservation_logits.txt = (L, A) matrix\\n\")\n",
        "  handle.write(\"coevolution.txt = (L, L) matrix\\n\")\n",
        "  handle.write(\"jac.npy = ((L*L-L)/2, A, A) tensor\\n\")\n",
        "  handle.write(\"jac index can be recreated with np.triu_indices(L,1)\\n\")\n",
        "  handle.write(f\"[A]lphabet: {ALPHABET}\\n\")\n",
        "  handle.write(f\"sequence: {sequence}\\n\")"
      ],
      "metadata": {
        "id": "0iY6qZdr7NLq",
        "outputId": "e12e26f8-f9a6-4b9c-9758-4be3439b9160",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(sequence)//4)"
      ],
      "metadata": {
        "id": "IYhHrkRoy2Xv",
        "outputId": "20efb636-835e-48ed-ed9d-1451f65a7ee2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##compute conservation\n",
        "\n",
        "logits = get_logits(sequence, p=PARALLEL)\n",
        "logits = logits[:,ALPHABET_map]\n",
        "np.savetxt(f\"output/conservation_logits_{model_name}.txt\",logits)\n",
        "pssm = softmax(logits,-1)\n",
        "df = pssm_to_dataframe(pssm, ALPHABET)\n",
        "\n",
        "# plot pssm\n",
        "num_colors = 256  # You can adjust this number\n",
        "palette = viridis(256)\n",
        "TOOLS = \"hover,save,pan,box_zoom,reset,wheel_zoom\"\n",
        "p = figure(title=\"CONSERVATION\",\n",
        "           x_range=[str(x) for x in range(1,len(sequence)+1)],\n",
        "           y_range=list(ALPHABET)[::-1],\n",
        "           width=900, height=400,\n",
        "           tools=TOOLS, toolbar_location='below',\n",
        "           tooltips=[('Position', '@Position'), ('Amino Acid', '@{Amino Acid}'), ('Probability', '@Probability')])\n",
        "\n",
        "r = p.rect(x=\"Position\", y=\"Amino Acid\", width=1, height=1, source=df,\n",
        "           fill_color=linear_cmap('Probability', palette, low=0, high=1),\n",
        "           line_color=None)\n",
        "p.xaxis.visible = False  # Hide the x-axis\n",
        "show(p)"
      ],
      "metadata": {
        "id": "vcWEjQApY5Fk",
        "outputId": "5215a0e1-2757-4aa6-aeaa-2a17671c5748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492,
          "referenced_widgets": [
            "3f97d6d3c538478db0340d049d39d04a",
            "b849e0da03a34d859b670b41cf53693f",
            "fe5299bf94024d62b29f1b0665774a40",
            "62fdb4848300453d9cc75eb394ed800c",
            "f2978d6ed73b4a1cbab1b40f6aafa23a",
            "02ba8f194664479c9ed9e4702792aaee",
            "47b3b4b977114daf82bf72ac36a6fbb2",
            "e0960c4d985d4858a3dba02f92faed0d",
            "22c6c5bf23b34519b77d8c3641983883",
            "41da03df75664d6bba98c454f3794274",
            "6edb57893f2643908c2ac56a135f7ba0"
          ]
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3552 [elapsed: 00:00 remaining: ?]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f97d6d3c538478db0340d049d39d04a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 9.41 GiB. GPU 0 has a total capacity of 14.74 GiB of which 1.79 GiB is free. Process 5634 has 12.95 GiB memory in use. Of the allocated memory 12.76 GiB is allocated by PyTorch, and 63.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-6-2851358103.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#@markdown ##compute conservation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPARALLEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mALPHABET_map\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"output/conservation_logits_{model_name}.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36mget_logits\u001b[0;34m(seq, p, return_jac)\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.cache/torch/hub/facebookresearch_esm_main/esm/model/esm2.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tokens, repr_layers, need_head_weights, return_contacts)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             x, attn = layer(\n\u001b[0m\u001b[1;32m    113\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0mself_attn_padding_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.cache/torch/hub/facebookresearch_esm_main/esm/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, self_attn_mask, self_attn_padding_mask, need_head_weights)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mresidual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mself_attn_layer_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         x, attn = self.self_attn(\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0mquery\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.cache/torch/hub/facebookresearch_esm_main/esm/multihead_attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, incremental_state, need_weights, static_kv, attn_mask, before_softmax, need_head_weights)\u001b[0m\n\u001b[1;32m    377\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m         \u001b[0mattn_weights_float\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monnx_trace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0mattn_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_weights_float\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         attn_probs = F.dropout(\n",
            "\u001b[0;32m~/.cache/torch/hub/facebookresearch_esm_main/esm/multihead_attention.py\u001b[0m in \u001b[0;36mutils_softmax\u001b[0;34m(x, dim, onnx_trace)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   2140\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2142\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2143\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 9.41 GiB. GPU 0 has a total capacity of 14.74 GiB of which 1.79 GiB is free. Process 5634 has 12.95 GiB memory in use. Of the allocated memory 12.76 GiB is allocated by PyTorch, and 63.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##compute coevolution\n",
        "#@markdown Set output `layer` and postprocessing options such as to `center`, [`symm`]etrize, remove [`diag`]onal and to perform average product correction `apc`.\n",
        "#@markdown The `fast` approximation only perturbs the mask token.\n",
        "fast = False # @param {type:\"boolean\"}\n",
        "layer = None # @param [\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\",\"31\",\"32\",\"33\",\"None\"] {type:\"raw\"}\n",
        "center = True # @param {type:\"boolean\"}\n",
        "symm = True # @param {type:\"boolean\"}\n",
        "diag = \"remove\" # @param [\"remove\", \"normalize\", \"none\"]\n",
        "apc = True # @param {type:\"boolean\"}\n",
        "settings = dict(layer=layer,\n",
        "                sequence=sequence,\n",
        "                fast=fast)\n",
        "if not \"jac\" in dir() or settings != settings_:\n",
        "  if fast and layer is None:\n",
        "    jac = get_logits(sequence, p=PARALLEL, return_jac=True)\n",
        "  else:\n",
        "    jac = get_categorical_jacobian(sequence, layer=layer, fast=fast)\n",
        "  settings_ = settings.copy()\n",
        "\n",
        "con = jac_to_con(jac, center=center, diag=diag, apc=apc)\n",
        "\n",
        "np.savetxt(f\"output/coevolution_{model_name}.txt\",con[\"contacts\"])\n",
        "if layer is not None:\n",
        "  i,j = np.triu_indices(len(sequence),1)\n",
        "  np.save(f\"output/jac_{model_name}.npy\",con[\"jac\"][i,:,j,:].astype(np.float16))\n",
        "\n",
        "df = contact_to_dataframe(con[\"contacts\"])\n",
        "TOOLS = \"hover,save,pan,box_zoom,reset,wheel_zoom\"\n",
        "p = figure(title=\"COEVOLUTION\",\n",
        "          x_range=[str(x) for x in range(1,len(sequence)+1)],\n",
        "          y_range=[str(x) for x in range(1,len(sequence)+1)][::-1],\n",
        "          width=800, height=800,\n",
        "          tools=TOOLS, toolbar_location='below',\n",
        "          tooltips=[('i', '@i'), ('j', '@j'), ('value', '@value')])\n",
        "\n",
        "r = p.rect(x=\"i\", y=\"j\", width=1, height=1, source=df,\n",
        "          fill_color=linear_cmap('value', gray, low=df.value.min(), high=df.value.max()),\n",
        "          line_color=None)\n",
        "p.xaxis.visible = False  # Hide the x-axis\n",
        "p.yaxis.visible = False  # Hide the x-axis\n",
        "show(p)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "jqNFriJzLCde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##show table of top covarying positions\n",
        "from google.colab import data_table\n",
        "\n",
        "sub_df = df[df[\"j\"]>df[\"i\"]].sort_values('value',ascending=False)\n",
        "data_table.DataTable(sub_df, include_index=False, num_rows_per_page=20, min_width=10)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8qn3WWtho8VN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown ##select pair of residues to investigate\n",
        "#@markdown Note: 1-indexed (first position is 1)\n",
        "\n",
        "position_i = 15 # @param {type:\"integer\"}\n",
        "position_j = 57 # @param {type:\"integer\"}\n",
        "if layer is None:\n",
        "  if fast:\n",
        "    print(\"this function is only supported when `fast=True`\")\n",
        "  else:\n",
        "    i = position_i - 1\n",
        "    j = position_j - 1\n",
        "    df = pair_to_dataframe(con[\"jac\"][i,:,j,:], ALPHABET)\n",
        "\n",
        "    # plot pssm\n",
        "    TOOLS = \"hover,save,pan,box_zoom,reset,wheel_zoom\"\n",
        "    p = figure(title=f\"coevolution between {position_i} {position_j}\",\n",
        "              x_range=list(ALPHABET),\n",
        "              y_range=list(ALPHABET)[::-1],\n",
        "              width=400, height=400,\n",
        "              tools=TOOLS, toolbar_location='below',\n",
        "              tooltips=[('aa_i', '@aa_i'), ('aa_j', '@aa_j'), ('value', '@value')])\n",
        "    p.xaxis.axis_label = f\"{sequence[i]}{position_i}\"\n",
        "    p.yaxis.axis_label = f\"{sequence[j]}{position_j}\"\n",
        "\n",
        "    r = p.rect(x=\"aa_i\", y=\"aa_j\", width=1, height=1, source=df,\n",
        "               fill_color=linear_cmap('value', bwr_r, low=-3.0, high=3.0),\n",
        "               line_color=None, dilate=True)\n",
        "    show(p)\n",
        "else:\n",
        "  print(\"this function is only supported when `layer=None`\")"
      ],
      "metadata": {
        "id": "t-0NBjgxXI1Y",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title download results (optional)\n",
        "from google.colab import files\n",
        "os.system(f\"zip -r output.zip output/\")\n",
        "files.download(f'output.zip')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "8HZ7bpwg63bN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}